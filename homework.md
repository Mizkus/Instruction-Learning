# Домашняя работа MLsysd

НГУ, осень 2025

## Общая информация

В качестве практической части курса вам нужно будет оформить одну задачу
машинного обучения в репозиторий со всеми необходимыми компонентами.
Смысл курса состоит в том, чтобы вы были способны самостоятельно
произвести все необходимые операции и получить конечный результат, а не
просто цифры и графики в jupyter notebook-е.

Мы будем разбирать устройство проекта для обучения нейронных сетей, т.к.
для них сейчас требуются наиболее продвинутые пайплайны.

Вам нужно будет описать выбранную задачу, создать репозиторий и работать
над ним постепенно, выполняя выданные задания с помощью коммитов в
основную ветку этого репозитория. Ссылку на репозиторий вы передадите
однажды, а далее я по ней буду проверять наличие сделанных заданий.

Задания на курс сразу выложены в этом файле, но приступать к ним вы
сможете после прохождения соответствующих тем (либо заранее, если что-то
уже знаете и умеете).

Проверка работ будет происходить по мере готовности работ по заданиям
(заданий всего 2).

**Крайний срок сдачи работ --- за 2 дня до даты экзамена.** Работы,
присланные позже, будут учитываться только на пересдаче. Это означает,
что если в семестре ничего не делать, а прийти только на экзамен (даже
со сделанной работой), то можно получить только баллы за экзамен и по
итогу отправиться на пересдачу.

Экзамен будет проходить устно с опорой на проект (будут задаваться
вопросы по нему, почему делали так, а не иначе, какие могут быть
варианты).

Также в начале каждой лекции будет небольшой тест по предыдущему
занятию. Они помогут вам вспомнить, что было в прошлый раз и настроиться
на продолжение разговора. Их результаты учитываются в итоговой оценке.

### Составные части оценки:

- **30%** --- проект\
- **60%** --- экзамен\
- **10%** --- тесты

### Границы оценок:

- **85%** --- отлично\
- **70%** --- хорошо\
- **55%** --- удовлетворительно

---

# Task 1: Project proposal

Необходимо выбрать тему проекта для дальнейшей реализации и описать
умеренно детально, что вы собираетесь делать. Тема будет обсуждаться на
первых занятиях.

## Шаблон описания проекта

### Как работать с шаблоном:

- Заполнить название проекта и своё ФИ.
- Название должно быть человекочитаемым.
- Сохранить структуру заголовков.
- Внутри каждого заголовка --- ваш текст (ссылки обязательны).
- Допускается работа командой до 5 человек.
- Проект должен быть уникальным.
- Данные должны быть реальными, не слишком маленькими.
- Нельзя использовать оформленные репозитории Kaggle winners или
  прошлых лет.
- Используем современные библиотеки (PyTorch; не sklearn).
- Используем нейросети.
- Данные должны быть реальными, не синтетическими.

## Источники вдохновения

- Дипломная работа
- Kaggle competitions
- Google Dataset Search

**Дедлайн выбора проекта: 15 октября**

---

# Task 2: Training code

Нужно создать открытый GitHub‑репозиторий, внутри которого --- валидный
Python‑пакет. Репозиторий должен реализовывать:

- загрузку данных\
- препроцессинг\
- обучение\
- подготовку к продакшену\
- инференс

### Как будет проходить проверка:

1.  Клонируем репозиторий\
2.  Создаём чистый virtualenv\
3.  Устанавливаем зависимости\
4.  `pre-commit install`\
5.  `pre-commit run -a` (ожидаем зелёный результат)\
6.  Запускаем обучение\
7.  Запускаем инференс

---

# Обязательные части проекта

## README.md \*

README --- инструкция по подключению участника к проекту.

### Должно быть:

#### 1. Смысловое описание проекта

Копия описания из Task 1 (скорректированная при необходимости).

#### 2. Техническая часть

**Setup** --- инструкция по настройке окружения (poetry / uv / conda)\
**Train** --- команды запуска обучения\
**Production preparation** --- экспорт в ONNX/TensorRT\
**Infer** --- запуск на новых данных

Код инференса должен иметь минимум зависимостей.

---

# Dependencies \*

- Использовать poetry или uv\
- Хранить зависимости в `pyproject.toml`\
- Lock-файл обязателен\
- Не должно быть лишних зависимостей

---

# Code quality tools \*

Обязательные инструменты:

- `pre-commit`\
- `black`\
- `isort`\
- `flake8`\
- `prettier` (для не-Python файлов)

`pre-commit run -a` должен проходить успешно.

---

# Training framework \*

Используем PyTorch Lightning (предпочтительно) или аналог, обсуждавшийся
на курсе. Обучение должно быть реализовано средствами фреймворка.

---

# Data management \*

Используем **DVC**.

Хранилище: - Google Drive\

- S3\
- локальное

DVC‑загрузка должна работать в командах train и infer.

Если используется локальное хранилище, нужно написать `download_data()`.

---

# Hydra \*

Все гиперпараметры --- в Hydra конфиги (`configs/`).

- структура по группам (preprocess / model / serving / etc.)\
- иерархия конфигов\
- никаких магических констант

---

# Logging \*

Необходимо логировать:

- метрики\
- функции потерь\
- гиперпараметры\
- git commit id

Используем:

- **MLflow** (сервер 127.0.0.1:8080)

Все графики и логи --- в директорию `plots/`.

Можно добавить wandb.

---

# Model production packaging

## ONNX (5 баллов)

Модель должна быть экспортирована в ONNX.

## TensorRT (5 баллов)

Оптимальный вариант --- конвертация из готового ONNX.

Оформление: отдельная CLI‑команда или shell‑скрипт.

---

# Inference server

Можно выбрать:

- **MLflow Serving** --- до 5 баллов\
- **Triton Inference Server** --- до 10 баллов

README должен содержать инструкции по запуску сервера.

---

# Типичные ошибки

### Нельзя:

- писать исполняемый код на уровне файла\
- `warnings.filterwarnings("ignore")`\
- сохранять данные и модели в git\
- давать репозиторию некорректные названия\
- давать пакету имя, не соответствующее правилам Python\
- использовать argparse (используйте fire / click / hydra)\
- использовать переменные из одной буквы (кроме i, j, k)

### Желательно:

- под `if __name__ == "__main__":` вызывать одну функцию\
- использовать fire с hydra compose api\
- иметь точку входа `commands.py`\
- использовать pathlib вместо os.path

---

# Заключение

Если что-то непонятно --- спрашивайте в чате. Правила --- это набор
хороших практик, которые нужно адаптировать под задачу и ситуацию.
